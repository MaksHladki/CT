<!doctype html>
<html lang="ru">

<head>
	<meta charset="utf-8">
	<title>Название лекции</title>
	<meta name="description" content="">
	<meta name="keywords" content="">
	<meta name="author" content="Maks Hladki">
	<meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
	<link rel="stylesheet" href="../../css/bundle.min.css">
	<!--[if lt IE 9]>
		<script src="../../js/html5shiv.min.js"></script>
	<![endif]-->
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section>
				<section>
					<h1>Название лекции</h1>
					<h3>Разработка динамичесих веб приложений</h3>
					<p>
						<small>Гладкий Максим Валерьевич / <a href="https://github.com/MaksHladki">github:MaksHladki</a></small>
					</p>
				</section>
				<section>
					<h2>Содержание лекции</h2>
					<nav id="presentable-toc" class="table-content"></nav>
				</section>
			</section>
			<section>
				<h1>Гипервизор</h1>
			</section>
			<section>
				<section>
					<h2>Гипервизор</h2>
					<blockquote>
						Гипервизор – это платформа виртуализации, позволяющая запускать на одном физическом компьютере несколько операционных систем.
						Именно гипервизор предоставляет изолированное окружение для каждой виртуальной машины, и именно он предоставляет гостевым
						ОС доступ к аппаратному обеспечению компьютера
					</blockquote>
					<p>https://habrahabr.ru/post/98580/</p>
				</section>
			</section>
			<section>
				<section>
					<h2>Типы гипервизора</h2>
					<ul>
						<li>Гипервизор 1 рода</li>
						<li></li>
					</ul>
				</section>
			</section>
			<section>
				<section>
					<h2>Гипервизор 1 рода</h2>
				</section>
				<section>
					<h3>Определение</h3>
					<blockquote>
						Гипервизор 1 типа запускается непосредственно на физическом «железе» и управляет им самостоятельно. Гостевые ОС, запущенные
						внутри виртуальных машин, располагаются уровнем выше
					</blockquote>
				</section>
				<section>
					<h3>Схема</h3>
					<img src="img/hypervisor_1.png" alt="">
				</section>
				<section>
					<h3>Особенности</h3>
					<ul>
						<li>Работает непосредственно с оборудованием (позволяет достичь большей производительности, надежности и безопасности)</li>
						<li>Имеет свои встроенные драйверы устройств, модели драйверов и планировщик</li>
						<li>Не зависит от базовой ОС</li>
						<li>Автономный, работает непосредственно в окружении усеченного ядра</li>
					</ul>
				</section>
				<section>
					<h3>Пример</h3>
					<ul>
						<li>VMware ESX</li>
						<li>Citrix</li>
						<li>XenServer</li>
					</ul>
				</section>
			</section>
			<section>
				<section>
					<h2>Гипервизор 2 типа</h2>
				</section>
				<section>
					<blockquote>
						Гипервизор второго типа (хостовый, монитор виртуальных машин) — специальный дополнительный программный слой, расположенный
						поверх основной хостовой ОС, который в основном выполняет функции управления гостевыми ОС, а эмуляцию и управление
						аппаратурой берет на себя хостовая ОС
					</blockquote>
				</section>
				<section>
					<h3>Схема</h3>
					<img src="img/hypervisor_2.png" alt="">
				</section>
				<section>
					<h3>Особенности</h3>
					<ul>
						<li>Виртуальные машины при этом запускаются в пользовательском пространстве хостовой ОС</li>
						<li>Более худший уровень производительности</li>
						<li></li>
						<li></li>
					</ul>
				</section>
				<section>
					<h3>Пример</h3>
					<ul>
						<li>MS Virtual Server</li>
						<li>VMware Server</li>
						<li>VirtualBox</li>
						<li>VMware Workstation</li>
						<li>QEMU</li>
						<li>Parallels</li>
					</ul>
				</section>
				<section>
				</section>
			</section>
			<section>
				<section>
					<h2>Гипервизор гибридный</h2>
				</section>
				<section>
					<h3>Определение</h3>
					<blockquote>
						Объединенный вариант первых двух, в котором функции управления аппаратными средствами выполняются тонким гипервизором и специальной
						депривилегированной сервисной ОС, работающей под управлением тонкого гипервизора. Обычно гипервизор управляет напрямую
						процессором и памятью компьютера, а через сервисную ОС гостевые ОС работают с остальными аппаратными компонентами
					</blockquote>
				</section>
				<section>
					<h3>Особенности</h3>
					<ul>
						<li> состоит из двух частей: из тонкого гипервизора, контролирующего процессор и память, а также работающей под его управлением
							специальной сервисной ОС в кольце пониженного уровня. Через сервисную ОС гостевые ОС получают доступ к физическому
							оборудованию.
						</li>
						<li>эффективен при высокой вычислительной нагрузке, когда используется только “тонкий” гипервизор, который в случае Microsoft
							занимает всего порядка 100 Кб оперативной памяти.</li>
						<li></li>
					</ul>
				</section>
				<section>
					<h3>Пример</h3>
					<ul>
						<li>Sun Logical Domains</li>
						<li>Xen</li>
						<li>Citrix XenServer</li>
						<li>Microsoft Hyper-V</li>
					</ul>
				</section>
			</section>
			<section>
				<section>
					<h2>Архитектура гипервизоров</h2>
				</section>
				<section>
					<h2>Монолитный гипервизор</h2>
					<blockquote>
						Гипервизоры монолитной архитектуры включают драйверы аппаратных устройств в свой код (см. рис. 3).
					</blockquote>
				</section>
				<section>
					<h3>Схема</h3>
					<img src="img/hypervisor_monolite.png" alt="">
				</section>
				<section>
					<h3>Преимущества</h3>
					<ul>
						<li>Более высокую (теоретически) производительность из-за нахождения драйверов в пространстве гипервизора</li>
						<li>Более высокую надежность, так как сбои в работе управляющей ОС (в терминах VMware – «Service Console») не приведет
							к сбою всех запущенных виртуальных машин.</li>
						<li></li>
						<li></li>
					</ul>
				</section>
				<section>
					<h3>Недостатки</h3>
					<ul>
						<li>Поддерживается только то оборудование, драйверы на которое имеются в гипервизоре. Из-за этого вендор гипервизора должен
							тесно сотрудничать с вендорами оборудования, чтобы драйвера для работы всего нового оборудования с гипервизором вовремя
							писались и добавлялись в код гипервизора. По той же причине при переходе на новую аппаратную платформу может понадобиться
							переход на другую версию гипервизора, и наоборот – при переходе на новую версию гипервизора может понадобиться смена
							аппаратной платформы, поскольку старое оборудование уже не поддерживается.</li>
						<li>Потенциально более низкая безопасность – из-за включения в гипервизор стороннего кода в виде драйверов устройств. Поскольку
							код драйверов выполняется в пространстве гипервизора, существует теоретическая возможность воспользоваться уязвимостью
							в коде и получить контроль как над хостовой ОС, так и над всеми гостевыми.</li>
						<li></li>
						<li></li>
					</ul>
					<blockquote>
						Самым распространенным примером монолитной архитектуры является VMware ESX.
					</blockquote>
				</section>
				<section>
					<h2>Микроядерная архитектура</h2>
					<blockquote>
						При микроядерной архитектуре драйверы устройств работают внутри хостовой ОС. Хостовая ОС в этом случае запускается в таком
						же виртуальном окружении, как и все ВМ, и именуется «родительской партицией». Все остальные окружения, соответственно
						– «дочерние». Единственная разница между родительской и дочерними партициями состоит в том, что только родительская
						партиция имеет непосредственный доступ к оборудованию сервера. Выделением памяти же и планировкой процессорного времени
						занимается сам гипервизор.
					</blockquote>
				</section>
				<section>
					<h3>Схема</h3>
					<blockquote>
						<img src="img/hypervisor_microkernel.png" alt="">
					</blockquote>
				</section>
				<section>
					<h3>Преимушества</h3>
					<ul>
						<li>Не требуются драйвера, «заточенные» под гипервизор. Гипервизор микроядерной архитектуры совместим с любым оборудованием,
							имеющим драйверы для ОС родительской партиции.</li>
						<li>Поскольку драйверы выполняются внутри родительской партиции – у гипервизора остается больше времени на более важные
							задачи – управление памятью и работу планировщика.</li>
						<li>Более высокая безопасность. Гипервизор не содержит постороннего кода, соответственно и возможностей для атаки на него
							становится меньше.</li>
						<li></li>
					</ul>
					<blockquote>
						Самым ярким примером микроядерной архитектуры является, собственно, сам Hyper-V.
					</blockquote>
				</section>
				<section>
					<h3>Распространенные платформы виртуализации</h3>
					<ul>
						<li>VMWARE (ESX, Server)</li>
						<li>CITRIX (Xen)</li>
						<li>Sun xVM (Virtual box)</li>
						<li>Microsoft (Hyper-V)</li>
						<li>Parallels (Parallels)</li>
						<li>Virtualiron (Virtualiron)</li>
					</ul>
				</section>
			</section>
			<section>
				<section>
					<h2>преимущества использования виртуализации</h2>
				</section>
				<section>
					<h3>Сокращение затрат на приобретение и поддержку оборудования</h3>
					<blockquote>
						В современных условиях практически в каждой компании всегда найдется один или два сервера имеющие несколько ролей, например,
						почтовый сервер, файловый сервер, сервер базы данных и т.д. Безусловно, на одной физической машине можно поднимать
						по несколько программных комплексов (серверов), выполняющих различные задачи. Но очень часто бывают ситуации, когда
						установка нового ПО требует независимой серверной единицы. В таком случае как раз и придет на выручку виртуальная машина
						с требуемой ОС. Сюда же можно отнести случаи, когда в сети необходимо иметь несколько независимых друг от друга виртуальных
						серверов со своим набором служб и своими характеристиками, которые должны существовать как независимые узлы сети. Типичный
						пример – это услуги VPS-хостинга.
					</blockquote>
				</section>
				<section>
					<h3>Сокращение серверного парка</h3>
					<blockquote>
						Преимущество виртуализации состоит в том, что можно значительно сократить количество физических ЭВМ. В результате меньше
						времени и денег тратится на поиск, закупку и замену оборудования. Наряду с этим сокращаются площади, выделяемые под
						содержание серверной базы.
					</blockquote>
				</section>
				<section>
					<h3>Сокращение штата IT-сотрудников</h3>
					<blockquote>
						На обслуживание меньшего количества физических ЭВМ требуется меньше людей. С точки зрения руководства компании, сокращение
						штата — это сокращение серьезной статьи расходов предприятия.
					</blockquote>
				</section>
				<section>
					<h3> Простота в обслуживании</h3>
					<blockquote>
						Добавить жесткий диск или расширить существующий, увеличить количество оперативной памяти, все это занимает определенное
						время в случае с физическим сервером. Отключение, отсоединение из стойки, подключение нового оборудования, включение
						– в случае использования виртуализации все эти действия опускаются, и операция сводится к нескольким щелчкам мыши или
						командам администратора.
					</blockquote>
				</section>
				<section>
					<h3>Клонирование и резервирование.</h3>
					<blockquote>
						Еще одним плюсом виртуализации является простота клонирования виртуальных машин. Например, компания открывает новый офис.
						При этом серверная инфраструктура центрального офиса стандартизирована и представляет собой несколько серверов с одинаковыми
						настройками. Развертывание такой инфраструктуры сводится к простому копированию образов на сервер нового офиса, конфигурировании
						сетевого оборудования и изменению настроек в прикладном ПО.
					</blockquote>
				</section>
			</section>
			<section>
				<h1>Понятие виртуальной машины</h1>
				<blockquote>
					http://www.intuit.ru/studies/courses/2324/624/lecture/13590
				</blockquote>
			</section>
			<section>
				<section>
					<h2>Сравнение платформ виртуализации</h2>
				</section>
				<section>
					<h3>Рынок гипервизоров</h3>
					<ul>
						<li>VMWare - 62%</li>
						<li>Microsoft - 27%</li>
						<li>Citrix - 8%</li>
						<li>Другие производители - 3%</li>
					</ul>
				</section>
				<section>
					<h3>Масштабируемость</h3>
					<table>
						<thead>
							<tr>
								<th>Ресурсы</th>
								<th>vSphere</th>
								<th>XenServer</th>
								<th>Hyper-V</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Логические ЦП</td>
								<td>320</td>
								<td>160</td>
								<td>320</td>
							</tr>
							<tr>
								<td>Виртуальные ЦП на хост</td>
								<td>4096</td>
								<td>4000</td>
								<td>2048</td>
							</tr>
							<tr>
								<td>Виртуальные ЦП на ВМ</td>
								<td>64</td>
								<td>16</td>
								<td>64</td>
							</tr>
							<tr>
								<td>Физическая ОЗУ</td>
								<td>4ТБ</td>
								<td>1ТБ</td>
								<td>4ТБ</td>
							</tr>
							<tr>
								<td>Озу на ВМ</td>
								<td>1ТБ</td>
								<td>128ГБ</td>
								<td>1ТБ</td>
							</tr>
							<tr>
								<td>Максимум ВМ</td>
								<td>15000</td>
								<td>1000</td>
								<td>8000</td>
							</tr>
						</tbody>
					</table>
				</section>
				<section>
					<h3>Производительность</h3>
					<table>
						<thead>
							<tr>
								<th>Возможности</th>
								<th>vSphere</th>
								<th>XenServer</th>
								<th>Hyper-V</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Виртуальный Fibre Channel</td>
								<td>Да</td>
								<td>Да</td>
								<td>Да</td>
							</tr>
							<tr>
								<td>Количество адаптеров FC</td>
								<td>256</td>
								<td>150</td>
								<td>4</td>
							</tr>
							<tr>
								<td>Максимальный размер диска</td>
								<td>64 ТБ</td>
								<td>2 ТБ</td>
								<td>64 ТБ</td>
							</tr>
							<tr>
								<td>Разгузка передачи данных</td>
								<td>Да</td>
								<td>Нет</td>
								<td>Да</td>
							</tr>
							<tr>
								<td>Динамическая память</td>
								<td>Да</td>
								<td>Да</td>
								<td>Да</td>
							</tr>
							<tr>
								<td>Качество обслуживания</td>
								<td>Да</td>
								<td>Нет</td>
								<td>Да</td>
							</tr>
						</tbody>
					</table>
				</section>
				<section>
					<h3>Механизмы отказоустоичивости</h3>
					<table>
						<thead>
							<tr>
								<th>Возможности</th>
								<th>vSphere</th>
								<th>XenServer</th>
								<th>Hyper-V</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Встроенный бекап</td>
								<td>Да</td>
								<td>Да</td>
								<td>Да</td>
							</tr>
							<tr>
								<td>Репликация ВМ</td>
								<td>Да</td>
								<td>Нет</td>
								<td>Да</td>
							</tr>
							<tr>
								<td>Мониторинг гостевых приложений</td>
								<td>Да</td>
								<td>Нет</td>
								<td>Да</td>
							</tr>
							<tr>
								<td>Обновление кластерных систем</td>
								<td>Да</td>
								<td>Да</td>
								<td>Да</td>
							</tr>
							<tr>
								<td>Шифрование дисков</td>
								<td>Да</td>
								<td>Нет</td>
								<td>Да</td>
							</tr>
						</tbody>
					</table>
				</section>
			</section>
			<section>
				<h1>Hyper-V</h1>
			</section>
			<section>
				<h2>История</h2>
				<p>https://ru.wikipedia.org/wiki/Microsoft_Hyper-V_Server</p>
				<ol>
					<li>2003 - Microsoft acquires Connectix</li>
					<li>2004 - Miscrosoft Visrtual Server 2005</li>
					<li>2005 - Microsoft Virtual Server 2005 R2</li>
					<li>2008 - Microsoft Hyper-V Server 2008</li>
					<li>2009 - Microsoft Hyper-V server 2008 R2</li>
					<li>2011 - Microsoft Hyper-V server 2008 R2 SP1</li>
					<li>2012 - Microsoft Hyper-V server 2012</li>
					<li>2013 - Microsoft Hyper-V server 2012 R2</li>
					<li>2016 - Microsoft Hyper-V server 2016</li>
				</ol>
			</section>
			<section>
				<h2>Типы виртуальных машин</h2>
				<ul>
					<li>BIOS based architecture - Generation 1</li>
					<li>EFI based architecture - Generation 2</li>
				</ul>
			</section>
			<section>
				<h2>Два способа развертывания</h2>
				<ul>
					<li>Как отдельная роль внутри ОС Windows</li>
					<li>Как самостоятельная ОС Windows Hyper-V Server</li>
				</ul>
			</section>
			<section>
				<section>
					<h2>Архитектура Hyper-V</h2>
				</section>
				<section>
					<h3>Общий вид</h3>
					<img src="img/Viridian_Architecture.svg" alt="" height="550">
				</section>
				<section>
					<h3>Еще пример</h3>
					<img src="img/hyperv_architecture.png" alt="">
					<blockquote>
						Как видно из рисунка, гипервизор работает на следующем уровне после железа – что характерно для гипервизоров 1 рода. Уровнем
						выше гипервизора работают родительская и дочерние партиции. Партиции в данном случае – это области изоляции, внутри
						которых работают операционные системы. Не нужно путать их, к примеру, с разделами на жестком диске. В родительской
						партиции запускается хостовая ОС (Windows Server 2008 R2) и стек виртуализации. Так же именно из родительской партиции
						происходит управление внешними устройствами, а так же дочерними партициями. Дочерние же партиции, как легко догадаться
						– создаются из родительской партиции и предназначены для запуска гостевых ОС. Все партиции связаны с гипервизором через
						интерфейс гипервызовов, предоставляющий операционным системам специальный API. Если кого-то из разработчиков интересуют
						подробности API гипервызовов — информация имеется в MSDN.
					</blockquote>
				</section>
				<section>
					<h3>Понятие раздела</h3>
					<blockquote>
						Hyper-V поддерживает разграничение согласно понятию раздел. Раздел — логическая единица разграничения, поддерживаемая гипервизором,
						в котором работают операционные системы
					</blockquote>
					<ul>
						<li>Hyper-V поддерживает разграничение согласно понятию раздел</li>
						<li>Каждый экземпляр гипервизора должен иметь один родительский раздел</li>
					</ul>
				</section>
				<section>
					<h3>Алгоритм работы виртуализации</h3>
					<ol>
						<li>стек виртуализации запускается на родительском разделе и обладает прямым доступом к аппаратным устройствам</li>
						<li>родительский раздел порождает дочерние разделы, на которых и располагаются гостевые ОС, при помощи API гипервизова</li>
						<li>дочерний раздел также может породить собственные дочерние разделы</li>
					</ol>
				</section>
				<section>
					<h3>Родительский раздел</h3>
					<img src="img/HV_родительский_раздел.png" alt="">
					<ul>
						<li>Родительский раздел создается системой в первую очередь, как только гипервизор начинает работу</li>
						<li>Родительский раздел используется для создания и управления дочерними разделами системы и включает WMI провайдера, предоставляющего
							интерфейс для удаленного администрирования.</li>
						<li>Родительский раздел управляет и распределяет аппаратные ресурсы, за исключением процесса физического распределения
							памяти, который осуществляется гипервизором</li>
						<li>Аппаратные ресурсы родительского раздела являются общими и выделяются для использования дочерними разделами</li>
						<li>Родительский раздел управляет питанием, "plug and play" - операциями и ведет журналы аппаратных сбоев.</li>
						<li></li>
					</ul>
				</section>
				<section>
					<h3>Стек виртуализации</h3>
					<blockquote>
						Ряд компонент, располагающийся в родительском разделе, называется стеком виртуализации. Стек виртуализации имеет прямой доступ
						к аппаратному обеспечению хостового компьютера. Стек виртуализации состоит из следующих компонент:
					</blockquote>
					<ul>
						<li>Служба управления виртуальными машинами (VMMS)</li>
						<li>Рабочие процессы виртуальных машин (VMWP)</li>
						<li>Виртуальные устройства</li>
						<li>Драйвер виртуальной инфраструктуры (VID)</li>
						<li>Библиотека интерфейсов гипервизора</li>
					</ul>
				</section>
				<section>
					<h3>Дочерний раздел (child partition)</h3>
					<blockquote>
						Как уже отмечалось, в рамках дочерних разделов функционируют гостевые операционные системы. Гипервизор первого типа поддерживает
						три основные типа дочерних разделов:
					</blockquote>
					<ul>
						<li>с операционной системой семейства Windows и установленными компонентами интеграции;</li>
						<li>с операционной системой, отличной от семейства Windows и с установленными компонентами интеграции;</li>
						<li>с операционной системой, не поддерживающей компоненты интеграции.</li>
					</ul>
				</section>
				<section>
					<h2>Состояния ВМ для службы VMMS</h2>
					<ul>
						<li>Starting</li>
						<li>Active</li>
						<li>Not Active</li>
						<li>Taking Snapshot</li>
						<li>Applying Snapshot</li>
						<li>Deleting Snapshot</li>
						<li>Merging Disk</li>
					</ul>
				</section>
				<section>
					<h2>Рабочий процесс виртуальной машины (VMWP)</h2>
					<blockquote>
						Для управления виртуальной машиной из родительской партиции запускается особый процесс – рабочий процесс виртуальной машины
						(VMWP). Процесс этот работает на уровне пользователя. Для каждой запущенной виртуальной машины служба VMMS запускает
						отдельный рабочий процесс. Это позволяет изолировать виртуальные машины друг от друга. Для повышения безопасности,
						рабочие процессы запускаются под встроенным пользовательским аккаунтом Network Service.
					</blockquote>
					<ul>
						<li>Создание, конфигурация и запуск виртуальной машины</li>
						<li>Пауза и продолжение работы (Pause/Resume)</li>
						<li>Сохранение и восстановление состояния (Save/Restore State)</li>
						<li>Создание моментальных снимков (снапшотов)</li>
						<li>Кроме того, именно рабочий процесс эмулирует виртуальную материнскую плату (VMB), которая используется для предоставления
							памяти гостевой ОС, управления прерываниями и виртуальными устройствами.</li>
					</ul>
				</section>
				<section>
					<h2>Виртуальные устройства</h2>
					<blockquote>
						Виртуальные устройства (VDevs) – это программные модули, реализующие конфигурацию и управление устройствами для виртуальных
						машин. VMB включает в себя базовый набор виртуальных устройств, включающий в себя шину PCI и системные устройства,
						идентичные чипсету Intel 440BX. Есть два типа виртуальных устройств:
					</blockquote>
					<ul>
						<li>Эмулируемые устройства – эмулируют определенные аппаратные устройства, такие, к примеру, как видеоадаптер VESA. Эмулируемых
							устройств достаточно много, к примеру: BIOS, DMA, APIC, шины ISA и PCI, контроллеры прерываний, таймеры, управление
							питанием, контроллеры последовательных портов, системный динамик, контроллер PS/2 клавиатуры и мыши, эмулируемый (Legacy)
							Ethernet-адаптер (DEC/Intel 21140), FDD, IDE-контроллер и видеоадаптер VESA/VGA. Именно поэтому для загрузки гостевой
							ОС может использоваться только виртуальный IDE-контроллер, а не SCSI, который является синтетическим устройством.</li>
						<li>
							Синтетические устройства – не эмулируют реально существующие в природе железки. Примерами служат синтетический видеоадаптер,
							устройства взаимодействия с человеком (HID), сетевой адаптер, SCSI-контроллер, синтетический контроллер прерывания
							и контроллер памяти. Синтетические устройства могут использоваться только при условии установки компонент интеграции
							в гостевой ОС. Синтетические устройства обращаются к аппаратным устройствам сервера посредством провайдеров служб
							виртуализации, работающих в родительской партиции. Обращение идет через виртуальную шину VMBus, что намного быстрее,
							чем эмуляция физических устройств.
						</li>
					</ul>
				</section>
				<section>
					<h2>Драйвер виртуальной инфраструктуры (VID)</h2>
					<blockquote>
						Драйвер виртуальной инфраструктуры (vid.sys) работает на уровне ядра и осуществляет управление партициями, виртуальными процессорами
						и памятью. Так же этот драйвер является промежуточным звеном между гипервизором и компонентами стека виртуализации
						уровня пользователя.
					</blockquote>
				</section>
				<section>
					<h2>Библиотека интерфейса гипервизора</h2>
					<blockquote>
						Библиотека интерфейса гипервизора (WinHv.sys) – это DLL уровня ядра, которая загружается как в хостовой, так и в гостевых
						ОС, при условии установки компонент интеграции. Эта библиотека предоставляет интерфейс гипервызовов, использующийся
						для взаимодействия ОС и гипервизора.
					</blockquote>
				</section>
				<section>
					<h2>
						Провайдеры служб виртуализации (VSP)
					</h2>
					<blockquote>
						Провайдеры служб виртуализации работают в родительской партиции и предоставляют гостевым ОС доступ к аппаратным устройствам
						через клиент служб виртуализации (VSC). Связь между VSP и VSC осуществляется через виртуальную шину VMBus.
					</blockquote>
				</section>
				<section>
					<h2>Шина виртуальных машин (VMBus)</h2>
					<blockquote>
						Назначение VMBus состоит в предоставлении высокоскоростного доступа между родительской и дочерними партициями, в то время
						как остальные способы доступа значительно медленнее из-за высоких накладных расходах при эмуляции устройств. Если гостевая
						ОС не поддерживает работу интеграционных компонент – приходится использовать эмуляцию устройств. Это означает, что
						гипервизору приходится перехватывать вызовы гостевых ОС и перенаправлять их к эмулируемым устройствам, которые, напоминаю,
						эмулируются рабочим процессом виртуальной машины. Поскольку рабочий процесс запускается в пространстве пользователя,
						использование эмулируемых устройств приводит к значительному снижению производительности по сравнению с использованием
						VMBus. Именно поэтому рекомендуется устанавливать компоненты интеграции сразу же после установки гостевой ОС. Как уже
						было сказано, при использовании VMBus взаимодействие между хостовой и гостевой ОС происходит по клиент-серверной модели.
						В родительской партиции запущены провайдеры служб виртуализации (VSP), которые являются серверной частью, а в дочерних
						партициях – клиентская часть – VSC. VSC перенаправляет запросы гостевой ОС через VMBus к VSP в родительской партиции,
						а сам VSP переадресовывает запрос драйверу устройства. Этот процесс взаимодействия абсолютно прозрачен для гостевой
						ОС.
					</blockquote>
				</section>
				<section>
					<h3>Архитектурные особенности</h3>
					<ul>
						<li>Виртуализированные разделы не имеют ни доступа к физическому процессору, не могут управлять прерываниями</li>
						<li>Вместо этого у них есть виртуальное представление процессора и гостевой виртуальный адрес, зависящий от конфигурации
							гипервизора
						</li>
						<li>Дочерние разделы не имеют непосредственного доступа к аппаратным ресурсам, но зато получают виртуальное представление
							ресурсов, называемое виртуальными устройствами. </li>
						<li>Любая попытка обращения к виртуальным устройствам перенаправляется через VMBus к устройствам родительского раздела,
							которые и обработают данный запрос. VMBus — это логический канал, осуществляющий взаимодействие между разделами. Ответ
							возвращается также через VMBus.</li>
						<li>Родительские разделы запускают провайдер сервиса виртуализации (Virtualization Service Provider или сокр. VSP), который
							соединяется с VMBus и обрабатывает запросы доступа к устройствам от дочерних разделов. Виртуальные устройства дочернего
							раздела работают с клиентом сервиса виртуализации (Virtualization Service Client или сокр. VSC), который перенаправляет
							запрос через VMBus к VSP родительского раздела. Этот процесс прозрачен для гостевой ОС.</li>
						<li>Гипервизор может определять подмножество процессоров для каждого раздела</li>
						<li>ипервизор управляет прерываниями процессора и перенаправляет их в соответствующий раздел, используя логический контроллер
							искусственных прерываний</li>
						<li>Hyper-V может аппаратно ускорять трансляцию адресов между различными гостевыми виртуальными адресными пространствами
							при помощи IOMMU (I/O Memory Management Unit — Устройство управления вводом-выводом памяти), которое работает независимо
							от аппаратного управления памятью, используемого процессором</li>
						<li>Виртуальные устройства также поддерживают технологию Windows Server Virtualization, называемую прогрессивный ввод-вывод
							(англ. Enlightened I/O), для накопителей, сетевых и графических подсистем в том числе. </li>
					</ul>
				</section>
			</section>
			<section>
				<h2></h2>
			</section>
			<section>
				<h2>Характеристики</h2>
				<ul>
					<lI>Масштабируемость, производительность и плотность</lI>
					<lI></lI>
					<lI></lI>
					<lI></lI>
					<lI></lI>
				</ul>
			</section>
			<section>
				<h2>Ключевые особенности хранилища</h2>
				<ul>
					<li>Поддержка Virtual Fiber Channel (доступ к Fiber Channel SAN из ВМ)</li>
					<li>Нативная поддержка 4-КВ (преимущество от более емких и надежных дисков)</li>
					<li>Размер Virtual Hard Disk до 64 ТВ</li>
					<li>Offloaded Data Transfer (ODX) - повышает быстродействие используя SAN</li>
				</ul>
			</section>
			<section>
				<h2>Улучшенное управление ресурсами</h2>
				<ul>
					<li>Улучшение Dynamic Memory (более высокий уровень консолидации ВМ)</li>
					<li>Resource Metering (лог истории использования ВМ)</li>
					<li>QUality of Service (QoS) (позволяет обеспечить SLA по производительности ВМ)</li>
					<li>Data Center Bridging (DCB) - объеденяет сетевой трафик для повышения QoS</li>
					<li></li>
				</ul>
			</section>
			<section>
				<h2>Повышение уровня безопасности и изоляции</h2>
				<ul>
					<li>Private Virtual LAN</li>
					<li>Защита от ARP Spoofing</li>
					<li>DHCP Guard Protection</li>
					<li>Virtual Port ACLs</li>
					<li>Trunk Mode to Virtual Machine</li>
					<li>Monitoring and Port Mirroroing</li>
					<li>Windows PowerShell / WMI Managment</li>
					<li>IPSec</li>
					<li>SR-IOV</li>
					<li>Dynamic Virtual Machine Queue</li>
					<li>Extensible Switch - открытая платформа для созданий расширений с использованием Windows API</li>
				</ul>
			</section>
			<section>
				<h2>Физическая безопасность</h2>
				<p>Bitloker encryption</p>
				<ul>
					<li>Шифрование локальных жестких дисков</li>
					<li>Шифрование кластерных дисков</li>
					<li>Шифрование Cluster Shared Volumes</li>
					<li>Изменение Volume level encryption</li>
				</ul>
			</section>
			<section>
				<h2>Уровни миграции ВМ</h2>
				<ul>
					<li>Live Migration - бысрая миграция ВМ без ограничений</li>
					<li>Live Storage Migration - миграция дисков</li>
					<li>Shared-Nothing Live Migration - перенос ВМ между узлами и кластерами</li>
				</ul>
			</section>
			<section>
				<section>
					<h2>Пример создания ВМ</h2>
				</section>
				<section>
					<h3>Установка Hyper-V</h3>
					<img src="img/HV_1.png" alt="" height="550">
				</section>
				<section>
					<h3>Hyper-V Manager</h3>
					<img src="img/HV_2.png" alt="" height="550">
				</section>
				<section>
					<h3>Hyper-V Manager</h3>
					<img src="img/HV_3.png" alt="" height="550">
				</section>
				<section>
					<h3>Создание новой ВМ</h3>
					<img src="img/HV_4.png" alt="" height="550">
				</section>
				<section>
					<h3>Название и путь</h3>
					<img src="img/HV_5.png" alt="" height="550">
				</section>
				<section>
					<h3>Выбор типа</h3>
					<img src="img/HV_6.png" alt="" height="550">
				</section>
				<section>
					<h3>Размер ОП</h3>
					<img src="img/HV_7.png" alt="" height="550">
				</section>
				<section>
					<h3>Настройка сети</h3>
					<img src="img/HV_8.png" alt="" height="550">
				</section>
				<section>
					<h3>Virtual Hard Disk</h3>
					<img src="img/HV_9.png" alt="" height="550">
				</section>
				<section>
					<h3>Дополнительные опции</h3>
					<img src="img/HV_10.png" alt="" height="550">
				</section>
				<section>
					<h3>Создание сетевого подключения</h3>
					<img src="img/HV_11.png" alt="" height="550">
				</section>
				<section>
					<h3>Настройка параметров подключения</h3>
					<img src="img/HV_12.png" alt="" height="550">
				</section>
				<section>
					<h3>Настройки ВМ: hardware</h3>
					<img src="img/HV_13.png" alt="" height="550">
				</section>
				<section>
					<h3>Настройки ВМ: firmware</h3>
					<img src="img/HV_14.png" alt="" height="550">
				</section>
				<section>
					<h3>Настройки ВМ: security</h3>
					<img src="img/HV_15.png" alt="" height="550">
				</section>
				<section>
					<h3>Настройки ВМ: memory</h3>
					<img src="img/HV_16.png" alt="" height="550">
				</section>
				<section>
					<h3>Настройки ВМ: processor</h3>
					<img src="img/HV_17.png" alt="" height="550">
				</section>
				<section>
					<h3>Настройки ВМ: SCSI</h3>
					<img src="img/HV_18.png" alt="" height="550">
				</section>
				<section>
					<h3>Настройки ВМ: network</h3>
					<img src="img/HV_19.png" alt="" height="550">
				</section>
				<section>
					<h3>Запуск ВМ</h3>
					<img src="img/HV_20.png" alt="" height="550">
				</section>
				<section>
					<h3>Установка ОС</h3>
					<img src="img/HV_21.png" alt="" height="550">
				</section>
				<section>
					<h3>Результат установки</h3>
					<img src="img/HV_22.png" alt="" height="550">
				</section>
			</section>
			<!-- Содержимое лекции -->
			<section>
				<h2 class="header-hide">Спасибо за внимание</h2>
				<img src="img/thanks.jpg" alt="" height="600">
			</section>
		</div>
	</div>
	<aside id="presentable-icon" class="revealjs">
		<a title="Содержание лекции" href="#/0/1">
			<i class="fa fa-list-ul fa-2x"></i>
		</a>
	</aside>
	<script src="../../js/bundle.min.js"></script>
</body>

</html>